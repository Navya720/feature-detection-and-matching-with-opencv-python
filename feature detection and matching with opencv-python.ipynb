{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c72ad380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\navya\\appdata\\roaming\\python\\python311\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from opencv-contrib-python) (1.24.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --user opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99c2f2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv_python in c:\\users\\navya\\anaconda3\\lib\\site-packages (4.8.1.78)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\navya\\anaconda3\\lib\\site-packages (from opencv_python) (1.24.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv_python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9288c0",
   "metadata": {},
   "source": [
    "# Method 1: Haris corner detection\n",
    "Haris corner detection is a method in which we can detect the corners of the image by sliding a slider box all over the image by finding the corners and it will apply a threshold and the corners will be marked in the image. This algorithm is mainly used to detect the corners of the image."
   ]
  },
  {
   "cell_type": "raw",
   "id": "ba1f089f",
   "metadata": {},
   "source": [
    "Syntax: \n",
    "\n",
    "cv2.cornerHarris(image, dest, blockSize, kSize, freeParameter, borderType)\n",
    "\n",
    "Parameters:  \n",
    "\n",
    "Image – The source image to detect the features\n",
    "Dest – Variable to store the output image\n",
    "Block size – Neighborhood size\n",
    "Ksize – Aperture parameter\n",
    "Border type: The pixel revealing type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "839a2381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing the libraries\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# reading the image and converting the image to b/w\n",
    "image = cv.imread(\"book.image.jpeg\")\n",
    "gry_img = cv.cvtColor(image,cv.COLOR_BGR2GRAY)\n",
    "gry_img =  np.float32(gry_img)\n",
    "\n",
    "# applying the function\n",
    "dst=cv.cornerHarris(gry_img,blockSize=2,ksize=3,k=0.04)\n",
    "\n",
    "#dilate to mark the corners\n",
    "dst=cv.dilate(dst,None)\n",
    "image[dst>0.01*dst.max()]=[0,255,0]\n",
    "\n",
    "cv.imshow(\"haris_corner\",image)\n",
    "cv.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9280d91f",
   "metadata": {},
   "source": [
    "# Method 2: Shi-Tomasi corner detection\n",
    "Shi and Tomasi came up with a different corner detection algorithm which is mostly similar to the Haris corner detection algorithm in which the only difference will be the kernel value in which we can find only the n strongest corners of the image. This can greatly help while we need only the limited and very important features of the image."
   ]
  },
  {
   "cell_type": "raw",
   "id": "ebe4e843",
   "metadata": {},
   "source": [
    "Syntax: \n",
    "\n",
    "cv2.goodFeaturesToTrack(image, maxc, Quality, maxD)\n",
    "\n",
    "Parameters:\n",
    "\n",
    "image – The source image we need to extract the features.\n",
    "maxc – Maximum number of corners we want [Negative values gives all the corners]\n",
    "Quality – Quality level parameter (preferred value=0.01)\n",
    "maxD – Maximum distance (preferred value=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdaae61d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the image and converting into B?W \n",
    "image = cv.imread(\"book.image.jpeg\") \n",
    "gray_image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# Applying the function \n",
    "corners = cv.goodFeaturesToTrack( \n",
    "gray_image, maxCorners=50, qualityLevel=0.02, minDistance=20) \n",
    "corners = np.float32(corners)\n",
    "\n",
    "for item in corners: \n",
    "    x, y = item[0] \n",
    "    x = int(x) \n",
    "    y = int(y) \n",
    "    cv.circle(image, (x, y), 6, (0, 255, 0), -1) \n",
    "    \n",
    "# Showing the image \n",
    "cv.imshow('good_features', image) \n",
    "cv.waitKey() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02484521",
   "metadata": {},
   "source": [
    "# Method 3: SIFT (Scale-Invariant Feature Transform)\n",
    "While Haris and shi-Tomasi are the algorithms to detect the corners of the image. SIFT is one of the important algorithms that detect objects irrelevant to the scale and rotation of the image and the reference. This helps a lot while we are comparing the real-world objects to an image though it is independent of the angle and scale of the image. This method will return the key points of the images which we need to mark in the image."
   ]
  },
  {
   "cell_type": "raw",
   "id": "f1ea9750",
   "metadata": {},
   "source": [
    "Syntax:  \n",
    "\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "kp, des = sift.detectAndCompute(gray_img, None)\n",
    "\n",
    "This function returns key points which we later use with drawkeypoints() method to draw the keypoints.\n",
    "\n",
    "Note: The circles in the image represent the keypoints, where the size of the circle directly represents the strength of the key points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1bae90f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the image and converting into B/W \n",
    "image = cv.imread('book.image.jpeg') \n",
    "gray_image = cv.cvtColor(image, cv.COLOR_BGR2GRAY) \n",
    "\n",
    "# Applying the function \n",
    "sift = cv.xfeatures2d.SIFT_create() \n",
    "kp, des = sift.detectAndCompute(gray_image, None) \n",
    "\n",
    "\n",
    "# Applying the function \n",
    "kp_image = cv.drawKeypoints(image, kp, None, color=( \n",
    "    0, 255, 0), flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS) \n",
    "cv.imshow('SIFT', kp_image) \n",
    "cv.waitKey() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b16d5c",
   "metadata": {},
   "source": [
    "# Method 4: FAST algorithm for corner detection\n",
    "SURF is fast when compared to SIFT but not as fast to use with real-time devices like mobile phones and surveillance cameras. So FAST algorithm was introduced with a very fast computing time. However FAST gives us only the key points and we may need to compute descriptors with other algorithms like SIFT and SURF. With a Fast algorithm, we can detect corners and also blobs."
   ]
  },
  {
   "cell_type": "raw",
   "id": "67067703",
   "metadata": {},
   "source": [
    "Syntax:\n",
    "\n",
    "fast = cv2.FastFeatureDetector_create()\n",
    "\n",
    "fast.setNonmaxSuppression(False)\n",
    "\n",
    "kp = fast.detect(gray_img, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c911a745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the image and converting into B/W \n",
    "image = cv.imread('book.image.jpeg') \n",
    "gray_image = cv.cvtColor(image, cv.COLOR_BGR2GRAY) \n",
    "\n",
    "\n",
    "# Applying the function \n",
    "fast = cv.FastFeatureDetector_create() \n",
    "fast.setNonmaxSuppression(False) \n",
    "\n",
    "\n",
    "# Drawing the keypoints \n",
    "kp = fast.detect(gray_image, None) \n",
    "kp_image = cv.drawKeypoints(image, kp, None, color=(0, 255, 0)) \n",
    "\n",
    "cv.imshow('FAST', kp_image) \n",
    "cv.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94289585",
   "metadata": {},
   "source": [
    "# Method 5: ORB (Oriented FAST and Rotated Brief)\n",
    "ORB is a very effective way of detecting the features of the image when compared to SIFT and SURF. ORB is programmed to find fewer features in the image when compared to the SIFT and SURF algorithm because it detects the very important features in less time than them yet this algorithm is considered as a very effective algorithm when compared to other detecting algorithms."
   ]
  },
  {
   "cell_type": "raw",
   "id": "3e021026",
   "metadata": {},
   "source": [
    "Syntax:  \n",
    "\n",
    "orb = cv2.ORB_create(nfeatures=2000)\n",
    "\n",
    "kp, des = orb.detectAndCompute(gray_img, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acb3aac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the image and converting into B/W \n",
    "image = cv.imread('book.image.jpeg') \n",
    "gray_image = cv.cvtColor(image, cv.COLOR_BGR2GRAY) \n",
    "\n",
    "# Applying the function \n",
    "orb = cv.ORB_create(nfeatures=2000) \n",
    "kp, des = orb.detectAndCompute(gray_image, None) \n",
    "\n",
    "# Drawing the keypoints \n",
    "kp_image = cv.drawKeypoints(image, kp, None, color=(0, 255, 0), flags=0) \n",
    "\n",
    "cv.imshow('ORB', kp_image) \n",
    "cv.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b81c4c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bb608f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
